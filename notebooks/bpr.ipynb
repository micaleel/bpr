{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T11:28:48.202124Z",
     "iopub.status.busy": "2020-09-30T11:28:48.201866Z",
     "iopub.status.idle": "2020-09-30T11:28:48.297945Z",
     "shell.execute_reply": "2020-09-30T11:28:48.297337Z",
     "shell.execute_reply.started": "2020-09-30T11:28:48.202099Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext blackcellmagic\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'pdf'\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext line_profiler\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T11:28:49.462293Z",
     "iopub.status.busy": "2020-09-30T11:28:49.462039Z",
     "iopub.status.idle": "2020-09-30T11:28:49.524204Z",
     "shell.execute_reply": "2020-09-30T11:28:49.522809Z",
     "shell.execute_reply.started": "2020-09-30T11:28:49.462268Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s]: %(message)s (%(filename)s:%(lineno)d)\",\n",
    "    level=logging.INFO,\n",
    "    datefmt=\"%H.%M.%S\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T11:28:51.498510Z",
     "iopub.status.busy": "2020-09-30T11:28:51.498240Z",
     "iopub.status.idle": "2020-09-30T11:28:51.556900Z",
     "shell.execute_reply": "2020-09-30T11:28:51.555996Z",
     "shell.execute_reply.started": "2020-09-30T11:28:51.498480Z"
    }
   },
   "outputs": [],
   "source": [
    "# from bpr import cli\n",
    "# from bpr.cli import train, Config, train_concurrently\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "from typing import List, Union, TypeVar, Any, Optional, List\n",
    "import bpr\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "from multiprocessing import cpu_count\n",
    "from bpr import plotting\n",
    "from matplotlib import cm\n",
    "import glob\n",
    "import pathlib\n",
    "from typing import Dict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_df = bpr.ml100k.load(subset=\"train\")\n",
    "tst_matrix = bpr.ml100k.load_matrix(subset=\"test\")\n",
    "trn_matrix = bpr.ml100k.load_matrix(subset=\"train\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "LR_ITEM = 0.05\n",
    "LR_USER = 0.05\n",
    "N_FACTORS = 10\n",
    "REG = 0.01\n",
    "SEED = 42\n",
    "TOP_N = 10\n",
    "WARM_UP = math.ceil(0.3 * EPOCHS)\n",
    "WINDOW_SIZE = math.ceil(0.1 * WARM_UP)\n",
    "WARM_UP = 20\n",
    "WINDOW_SIZE = 5\n",
    "q = WINDOW_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_dict = {}\n",
    "ptrain = partial(\n",
    "    bpr.training.train,\n",
    "    train_df=train_df,\n",
    "    trn_matrix=trn_matrix,\n",
    "    tst_matrix=tst_matrix,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    lr_user=LR_USER,\n",
    "    lr_item=LR_ITEM,\n",
    "    n_factors=N_FACTORS,\n",
    "    reg=REG,\n",
    "    warm_up=WARM_UP,\n",
    "    window_size=WINDOW_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12.36.29]: sampler=RandomSampler, batch_size=32, epochs=200, lr_item=0.05, lr_user=0.05, n_factors=10, reg=0.01, method=std, rand_option=cached, reverse=True, se_0=100, se_end=10, seed=42, top_n=10, warm_up=20, window_size=5 (training.py:166)\n",
      "[12.36.29]: seed=42 (_base.py:29)\n",
      "[12.36.29]: sampler: RandomSampler (training.py:67)\n",
      "[12.36.31]: Using RandomSampler (training.py:87)\n",
      "[12.36.31]: Epoch   1 (utils.py:112)\n",
      "[12.37.00]: Epoch  20 (utils.py:112)\n",
      "[12.37.31]: Epoch  40 (utils.py:112)\n",
      "[12.38.01]: Epoch  60 (utils.py:112)\n",
      "[12.38.32]: Epoch  80 (utils.py:112)\n",
      "[12.39.03]: Epoch 100 (utils.py:112)\n"
     ]
    }
   ],
   "source": [
    "summaries_dict[\"RandomSampler\"] = ptrain(\n",
    "    sampler=\"RandomSampler\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10.56.35]: sampler=RecencyBias, batch_size=32, epochs=200, lr_item=0.05, lr_user=0.05, n_factors=10, reg=0.01, method=grad, rand_option=cached, reverse=True, se_0=1, se_end=10, seed=42, top_n=10, warm_up=20, window_size=5 (training.py:166)\n",
      "[10.56.35]: seed=42 (_base.py:29)\n",
      "[10.56.35]: reverse=True, rand_option=cached (online.py:57)\n",
      "[10.56.35]: [RecencyBias] warm_up=20, q=5, se_0=1, se_end=10, discount_warm_up=True, reverse=True, rand_option=cached, method=grad (recency.py:81)\n",
      "[10.56.35]: sampler: RecencyBias (training.py:67)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 338 µs, sys: 22 µs, total: 360 µs\n",
      "Wall time: 24.1 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10.56.38]: Using RecencyBias (training.py:87)\n",
      "[10.56.38]: Epoch   1 (utils.py:112)\n",
      "[10.57.10]: Epoch  20 (utils.py:112)\n",
      "[10.59.00]: Epoch  40 (utils.py:112)\n",
      "[11.00.59]: Epoch  60 (utils.py:112)\n",
      "[11.02.59]: Epoch  80 (utils.py:112)\n",
      "[11.04.58]: Epoch 100 (utils.py:112)\n",
      "[11.06.58]: Epoch 120 (utils.py:112)\n",
      "[11.08.57]: Epoch 140 (utils.py:112)\n",
      "[11.10.57]: Epoch 160 (utils.py:112)\n",
      "[11.12.55]: Epoch 180 (utils.py:112)\n",
      "[11.14.55]: Epoch 200 (utils.py:112)\n",
      "[11.15.01]: Finished in 1105 seconds (training.py:135)\n",
      "[11.15.01]: sampler=OnlineSampler, batch_size=32, epochs=200, lr_item=0.05, lr_user=0.05, n_factors=10, reg=0.01, method=grad, rand_option=cached, reverse=True, se_0=1, se_end=10, seed=42, top_n=10, warm_up=20, window_size=5 (training.py:166)\n",
      "[11.15.01]: seed=42 (_base.py:29)\n",
      "[11.15.01]: reverse=True, rand_option=cached (online.py:57)\n",
      "[11.15.01]: sampler: OnlineSampler (training.py:67)\n",
      "[11.15.05]: Using OnlineSampler (training.py:87)\n",
      "[11.15.05]: Epoch   1 (utils.py:112)\n",
      "[11.15.38]: Epoch  20 (utils.py:112)\n",
      "[11.16.28]: Epoch  40 (utils.py:112)\n",
      "[11.17.19]: Epoch  60 (utils.py:112)\n",
      "[11.18.09]: Epoch  80 (utils.py:112)\n",
      "[11.19.00]: Epoch 100 (utils.py:112)\n",
      "[11.19.51]: Epoch 120 (utils.py:112)\n",
      "[11.20.41]: Epoch 140 (utils.py:112)\n",
      "[11.21.32]: Epoch 160 (utils.py:112)\n",
      "[11.22.24]: Epoch 180 (utils.py:112)\n",
      "[11.23.16]: Epoch 200 (utils.py:112)\n",
      "[11.23.18]: Finished in 497 seconds (training.py:135)\n",
      "[11.23.18]: sampler=RecencyBias, batch_size=32, epochs=200, lr_item=0.05, lr_user=0.05, n_factors=10, reg=0.01, method=grad, rand_option=cached, reverse=True, se_0=1, se_end=100.0, seed=42, top_n=10, warm_up=20, window_size=5 (training.py:166)\n",
      "[11.23.18]: seed=42 (_base.py:29)\n",
      "[11.23.18]: reverse=True, rand_option=cached (online.py:57)\n",
      "[11.23.18]: [RecencyBias] warm_up=20, q=5, se_0=1, se_end=100, discount_warm_up=True, reverse=True, rand_option=cached, method=grad (recency.py:81)\n",
      "[11.23.18]: sampler: RecencyBias (training.py:67)\n",
      "[11.23.25]: Using RecencyBias (training.py:87)\n",
      "[11.23.25]: Epoch   1 (utils.py:112)\n",
      "[11.23.56]: Epoch  20 (utils.py:112)\n",
      "[11.25.43]: Epoch  40 (utils.py:112)\n",
      "[11.27.41]: Epoch  60 (utils.py:112)\n",
      "[11.29.39]: Epoch  80 (utils.py:112)\n",
      "[11.31.37]: Epoch 100 (utils.py:112)\n",
      "[11.33.35]: Epoch 120 (utils.py:112)\n",
      "[11.35.32]: Epoch 140 (utils.py:112)\n",
      "[11.37.29]: Epoch 160 (utils.py:112)\n",
      "[11.39.26]: Epoch 180 (utils.py:112)\n",
      "[11.41.23]: Epoch 200 (utils.py:112)\n",
      "[11.41.29]: Finished in 1090 seconds (training.py:135)\n",
      "[11.41.29]: sampler=OnlineSampler, batch_size=32, epochs=200, lr_item=0.05, lr_user=0.05, n_factors=10, reg=0.01, method=grad, rand_option=cached, reverse=True, se_0=1, se_end=100.0, seed=42, top_n=10, warm_up=20, window_size=5 (training.py:166)\n",
      "[11.41.29]: seed=42 (_base.py:29)\n",
      "[11.41.29]: reverse=True, rand_option=cached (online.py:57)\n",
      "[11.41.29]: sampler: OnlineSampler (training.py:67)\n",
      "[11.41.37]: Using OnlineSampler (training.py:87)\n",
      "[11.41.37]: Epoch   1 (utils.py:112)\n",
      "[11.42.10]: Epoch  20 (utils.py:112)\n",
      "[11.42.59]: Epoch  40 (utils.py:112)\n",
      "[11.43.50]: Epoch  60 (utils.py:112)\n",
      "[11.44.40]: Epoch  80 (utils.py:112)\n",
      "[11.45.31]: Epoch 100 (utils.py:112)\n",
      "[11.46.22]: Epoch 120 (utils.py:112)\n",
      "[11.47.13]: Epoch 140 (utils.py:112)\n",
      "[11.48.04]: Epoch 160 (utils.py:112)\n",
      "[11.48.54]: Epoch 180 (utils.py:112)\n",
      "[11.49.45]: Epoch 200 (utils.py:112)\n",
      "[11.49.48]: Finished in 498 seconds (training.py:135)\n",
      "[11.49.48]: sampler=RecencyBias, batch_size=32, epochs=200, lr_item=0.05, lr_user=0.05, n_factors=10, reg=0.01, method=grad, rand_option=cached, reverse=True, se_0=100.0, se_end=1, seed=42, top_n=10, warm_up=20, window_size=5 (training.py:166)\n",
      "[11.49.48]: seed=42 (_base.py:29)\n",
      "[11.49.48]: reverse=True, rand_option=cached (online.py:57)\n",
      "[11.49.48]: [RecencyBias] warm_up=20, q=5, se_0=100, se_end=1, discount_warm_up=True, reverse=True, rand_option=cached, method=grad (recency.py:81)\n",
      "[11.49.48]: sampler: RecencyBias (training.py:67)\n",
      "[11.49.58]: Using RecencyBias (training.py:87)\n",
      "[11.49.58]: Epoch   1 (utils.py:112)\n",
      "[11.50.31]: Epoch  20 (utils.py:112)\n",
      "[11.52.20]: Epoch  40 (utils.py:112)\n",
      "[11.54.20]: Epoch  60 (utils.py:112)\n",
      "[11.56.15]: Epoch  80 (utils.py:112)\n",
      "[11.58.11]: Epoch 100 (utils.py:112)\n",
      "[12.00.09]: Epoch 120 (utils.py:112)\n",
      "[12.02.10]: Epoch 140 (utils.py:112)\n",
      "[12.04.11]: Epoch 160 (utils.py:112)\n",
      "[12.06.12]: Epoch 180 (utils.py:112)\n",
      "[12.08.13]: Epoch 200 (utils.py:112)\n",
      "[12.08.19]: Finished in 1110 seconds (training.py:135)\n",
      "[12.08.19]: sampler=OnlineSampler, batch_size=32, epochs=200, lr_item=0.05, lr_user=0.05, n_factors=10, reg=0.01, method=grad, rand_option=cached, reverse=True, se_0=100.0, se_end=1, seed=42, top_n=10, warm_up=20, window_size=5 (training.py:166)\n",
      "[12.08.19]: seed=42 (_base.py:29)\n",
      "[12.08.19]: reverse=True, rand_option=cached (online.py:57)\n",
      "[12.08.19]: sampler: OnlineSampler (training.py:67)\n",
      "[12.08.31]: Using OnlineSampler (training.py:87)\n",
      "[12.08.31]: Epoch   1 (utils.py:112)\n",
      "[12.09.04]: Epoch  20 (utils.py:112)\n",
      "[12.09.54]: Epoch  40 (utils.py:112)\n",
      "[12.10.48]: Epoch  60 (utils.py:112)\n",
      "[12.11.40]: Epoch  80 (utils.py:112)\n",
      "[12.12.32]: Epoch 100 (utils.py:112)\n",
      "[12.13.25]: Epoch 120 (utils.py:112)\n",
      "[12.14.19]: Epoch 140 (utils.py:112)\n",
      "[12.15.11]: Epoch 160 (utils.py:112)\n",
      "[12.16.03]: Epoch 180 (utils.py:112)\n",
      "[12.16.54]: Epoch 200 (utils.py:112)\n",
      "[12.16.57]: Finished in 518 seconds (training.py:135)\n",
      "[12.16.57]: sampler=RecencyBias, batch_size=32, epochs=200, lr_item=0.05, lr_user=0.05, n_factors=10, reg=0.01, method=grad, rand_option=cached, reverse=True, se_0=10, se_end=1, seed=42, top_n=10, warm_up=20, window_size=5 (training.py:166)\n",
      "[12.16.57]: seed=42 (_base.py:29)\n",
      "[12.16.57]: reverse=True, rand_option=cached (online.py:57)\n",
      "[12.16.57]: [RecencyBias] warm_up=20, q=5, se_0=10, se_end=1, discount_warm_up=True, reverse=True, rand_option=cached, method=grad (recency.py:81)\n",
      "[12.16.57]: sampler: RecencyBias (training.py:67)\n",
      "[12.17.10]: Using RecencyBias (training.py:87)\n",
      "[12.17.10]: Epoch   1 (utils.py:112)\n",
      "[12.17.43]: Epoch  20 (utils.py:112)\n",
      "[12.19.32]: Epoch  40 (utils.py:112)\n",
      "[12.21.29]: Epoch  60 (utils.py:112)\n",
      "[12.23.29]: Epoch  80 (utils.py:112)\n",
      "[12.25.27]: Epoch 100 (utils.py:112)\n",
      "[12.27.27]: Epoch 120 (utils.py:112)\n",
      "[12.29.26]: Epoch 140 (utils.py:112)\n",
      "[12.31.26]: Epoch 160 (utils.py:112)\n",
      "[12.33.26]: Epoch 180 (utils.py:112)\n",
      "[12.35.22]: Epoch 200 (utils.py:112)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f91a27e8868b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mse_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mse_end\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mse_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     summaries_dict[\"RB_{}_{}_{}\".format(int(se_0), int(se_end), desc)] = ptrain(\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RecencyBias\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mse_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mse_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mse_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mse_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     summaries_dict[\"OS_{}_{}_{}\".format(int(se_0), int(se_end), desc)] = ptrain(\n",
      "\u001b[0;32m~/bpr/bpr/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_df, trn_matrix, tst_matrix, sampler, batch_size, epochs, lr_item, lr_user, n_factors, reg, method, rand_option, reverse, se_0, se_end, seed, top_n, warm_up, window_size)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mlr_item\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_item\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;32m~/bpr/bpr/training.py\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(df, tst_matrix, trn_matrix, batch_size, n_factors, topn, epochs, lr_user, lr_item, reg, sampler, verbose)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mprint_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mepoch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mprint_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEpochPrinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"  Batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bpr/bpr/samplers/recency.py\u001b[0m in \u001b[0;36mon_epoch_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# recent = np.vstack(recent_arr).astype(np.float16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mrecent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             assert recent.shape[0] == self.n_samples, (\n\u001b[1;32m    115\u001b[0m                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" != \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time\n",
    "se_params = [\n",
    "    (1, 10),\n",
    "    (1, 1e2),\n",
    "    (1e2, 1),\n",
    "    (10, 1),\n",
    "]\n",
    "method = bpr._types.Methods.GRAD.value\n",
    "desc = method\n",
    "for se_0, se_end in se_params:\n",
    "    summaries_dict[\"RB_{}_{}_{}\".format(int(se_0), int(se_end), desc)] = ptrain(\n",
    "        sampler=\"RecencyBias\", se_0=se_0, se_end=se_end, method=method\n",
    "    )\n",
    "    summaries_dict[\"OS_{}_{}_{}\".format(int(se_0), int(se_end), desc)] = ptrain(\n",
    "        sampler=\"OnlineSampler\", se_0=se_0, se_end=se_end, method=method\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_gains(summaries_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_dict['RandomSampler'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(summaries_dict.keys()))\n",
    "exclude = None\n",
    "bpr.plotting.plot_convergence_quadrant(\n",
    "    summaries_dict, exclude=exclude, fontsize=\"medium\", warm_up=WARM_UP, figsize=(15, 5.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using CLI tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T11:29:25.913608Z",
     "iopub.status.busy": "2020-09-30T11:29:25.913360Z",
     "iopub.status.idle": "2020-09-30T11:29:25.978257Z",
     "shell.execute_reply": "2020-09-30T11:29:25.977145Z",
     "shell.execute_reply.started": "2020-09-30T11:29:25.913581Z"
    }
   },
   "outputs": [],
   "source": [
    "bpr.cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T11:29:17.569380Z",
     "iopub.status.busy": "2020-09-30T11:29:17.569163Z",
     "iopub.status.idle": "2020-09-30T11:29:17.642657Z",
     "shell.execute_reply": "2020-09-30T11:29:17.641505Z",
     "shell.execute_reply.started": "2020-09-30T11:29:17.569351Z"
    }
   },
   "outputs": [],
   "source": [
    "workers = math.ceil(cpu_count() * 0.5)\n",
    "configurations = bpr.cli.Config.parse(\"../config.yaml\")\n",
    "config_filenames = sorted(set([c.filename() for c in configurations]))\n",
    "pprint(config_filenames[:10])\n",
    "# train_concurrently(data=\"../data/\", workers=workers, configurations=configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(json.load(open(\"processed.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = pathlib.Path(\"../data/outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(fname: pathlib.Path):\n",
    "    try:\n",
    "        dataset, sampler, method, rand_option, others = fname.name.split(\"-\")\n",
    "    except ValueError:\n",
    "        print(fname.name)\n",
    "        dataset, sampler, others = fname.name.split(\"-\")\n",
    "        method = 'default'\n",
    "        rand_option = 'default'\n",
    "\n",
    "    def fname_to_dict() -> Dict:\n",
    "        parts = dict()\n",
    "        prefixes = {\n",
    "            \"bs\": (int, \"batch_size\"),\n",
    "            \"ep\": (int, \"epochs\"),\n",
    "            \"li\": (float, \"lr_item\"),\n",
    "            \"lu\": (float, \"lr_user\"),\n",
    "            \"nf\": (int, \"n_factors\"),\n",
    "            \"rg\": (float, \"reg\"),\n",
    "            \"rv\": (bool, \"reverse\"),\n",
    "            \"wu\": (int, \"warm_up\"),\n",
    "            \"se0\": (int, \"se_0\"),\n",
    "            \"send\": (int, \"se_end\"),\n",
    "            \"ws\": (int, \"window_size\"),\n",
    "        }\n",
    "        for prefix, class_and_alias in prefixes.items():\n",
    "            if prefix not in others:\n",
    "                continue\n",
    "            cls, alias = class_and_alias\n",
    "\n",
    "            pattern = r\"{}(\\d+).*\"\n",
    "            if prefix == \"rv\":\n",
    "                pattern = r\"{}(\\w).*\"\n",
    "\n",
    "            parts[alias] = re.findall(pattern.format(prefix), others)[0]\n",
    "\n",
    "            if cls is float and parts[alias].startswith(\"0\"):\n",
    "                z = list(parts[alias])\n",
    "                z.insert(1, \".\")\n",
    "                parts[alias] = \"\".join(z)\n",
    "            parts[alias] = cls(parts[alias])\n",
    "\n",
    "        return parts\n",
    "    sampler_lookups = {'rec': 'RecencyBias', 'ran': 'RandomSampler', 'onl': 'OnlineSampler'}\n",
    "    parsed = fname_to_dict()\n",
    "    parsed['dataset'] = dataset.replace(\"mk\", \"ml-100k\")\n",
    "    parsed['method'] = method.replace(\"mn\", 'mean')\n",
    "    parsed['rand_option'] = rand_option.replace(\"ca\", \"cached\")\n",
    "    parsed['sampler'] = sampler_lookups.get(sampler, sampler)\n",
    "    df = pd.read_feather(fname.as_posix())\n",
    "    df['experiment'] = fname.name.split(\".\")[0]\n",
    "    return df, parsed\n",
    "\n",
    "\n",
    "def _fn():\n",
    "    for idx, fname in enumerate(output_dir.resolve().glob(\"*.feather\")):\n",
    "        df, params = parse(fname)\n",
    "        df['label'] = idx\n",
    "        for k, v in params.items():\n",
    "            df[k] = v\n",
    "        yield df\n",
    "        \n",
    "df_all = pd.concat(_fn())\n",
    "\n",
    "display(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = sorted(\n",
    "    [\n",
    "        x\n",
    "        for x in df_all[\"experiment\"].unique()\n",
    "        if x.startswith(\"mk-rec\") or x.startswith(\"mk-ran\")\n",
    "    ]\n",
    ")\n",
    "pprint(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.experiment.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filenames = [c.split(\".\")[0] for c in config_filenames]\n",
    "df_all = df_all[df_all.experiment.isin(config_filenames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0.axhline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np.random.randn(5)).rolling(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint([x for x in dir(mcolors) if x.endswith(\"_COLORS\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcolors.CSS4_COLORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np.random.randn(5)).rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"HR@10\"\n",
    "\n",
    "\n",
    "def get_best_perfs(df_all: pd.DataFrame, exclude: Optional[List[str]]=None) -> pd.DataFrame:\n",
    "    def _g():\n",
    "        for experiment, df in df_all.groupby(\"experiment\"):\n",
    "            if exclude and any(s in experiment for s in exclude):\n",
    "                continue\n",
    "            best = df[metric].max()\n",
    "            best_idx = df[df[metric] == best].index[0]\n",
    "            best_values[experiment] = BestPerf(\n",
    "                experiment=experiment, value=best, epoch=best_idx\n",
    "            )\n",
    "            yield {\"experiment\": experiment, metric: best, \"epoch\": best_idx}\n",
    "    return pd.DataFrame(_g()).set_index('experiment')\n",
    "\n",
    "df_best = get_best_perfs(df_all, exclude=['-sd-', '-mn-'])\n",
    "df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.markers import MarkerStyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKERS = list(MarkerStyle.markers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "markers = dict(zip(df_best.index, MARKERS[: df_best.shape[0]]))\n",
    "sns.scatterplot(\n",
    "    y=metric,\n",
    "    x=\"epoch\",\n",
    "    hue=\"experiment\",\n",
    "    data=df_best.reset_index(),\n",
    "#     legend='brief',\n",
    "    markers=markers,\n",
    "    ax=ax,\n",
    "    s=900,\n",
    "    marker=\".\",\n",
    ")\n",
    "ax.legend(bbox_to_anchor=(1,1))\n",
    "ax.grid(color=\"gainsboro\", ls=\":\")\n",
    "highest_epoch = df_best['epoch'].max()\n",
    "lowest_epoch = df_best['epoch'].min()\n",
    "ax.set_xlim(\n",
    "    xmax=min(220, highest_epoch + 0.35 * highest_epoch),\n",
    "    xmin=lowest_epoch - 0.35 * lowest_epoch,\n",
    ")\n",
    "highest_metric = df_best[metric].max()\n",
    "lowest_metric = df_best[metric].min()\n",
    "ax.set_ylim(\n",
    "    ymax=highest_metric + 0.01 * highest_metric,\n",
    "    ymin=lowest_metric - 0.01 * lowest_metric,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(np.random.randn(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax0 = plt.subplots(figsize=(10, 6), nrows=1, sharex=True)\n",
    "criteria = \"experiment in @experiments\"\n",
    "exclude = [\"sd\", \"mk-ran\", \"se0100send1\"]\n",
    "for label, df in df_all.query(criteria).groupby(\"experiment\"):\n",
    "    if any(s in label for s in exclude):\n",
    "        continue\n",
    "\n",
    "    label_short = (\n",
    "        label.replace(\"mk-\", \"\")\n",
    "        .replace(\"ca-\", \"\")\n",
    "        .replace(\"bs32ep200li005lu005nf10rg001\", \"\")\n",
    "        .replace(\"rvT\", \"\")\n",
    "    )\n",
    "    df_ = df.set_index(\"epoch\")\n",
    "    _df_ran = df_all.query('experiment == \"mk-ran-bs32ep200li005lu005nf10rg001\"')[\n",
    "        \"HR@10\"\n",
    "    ]\n",
    "    _df = 100 * ((df[\"HR@10\"] - _df_ran) / _df_ran)\n",
    "    first_max_loc = df_[df_[\"HR@10\"] == df_[\"HR@10\"].max()].index[0]\n",
    "    #     _df.loc[:first_max_loc].rolling(10).max().plot(ax=ax0, label=label_short, alpha=0.9)\n",
    "    _df.loc[:first_max_loc].plot(ax=ax0, label=label_short, alpha=0.9, lw=5)\n",
    "    ax0.axhline(y=_df.max(), xmax=first_max_loc, lw=0.5, ls=\"dashed\")\n",
    "    #     df.set_index(\"epoch\")[\"HR@10\"].plot(ax=ax0, label=label_short, alpha=0.9)\n",
    "\n",
    "    #     pd.DataFrame(summaries_dict[\"RandomSampler\"])[\"HR@10\"].plot(\n",
    "    #         ax=ax0, label=\"From NB\", color=\"red\"\n",
    "    #     )\n",
    "    ax0.set_ylabel(\"HR@10\")\n",
    "\n",
    "#     ax1.set_ylim(0, 1)\n",
    "#     df.set_index(\"epoch\")[\"loss_avg\"].plot(ax=ax1, label=label_short, alpha=0.9)\n",
    "#     pd.DataFrame(summaries_dict[\"RandomSampler\"])[\"loss_avg\"].plot(\n",
    "#         ax=ax1, label=\"From NB\", color=\"red\"\n",
    "#     )\n",
    "#     ax1.set_ylabel(\"Avg Loss\")\n",
    "plt.gca().legend()\n",
    "fig.tight_layout()\n",
    "ax0.set_xlim(0, 200)\n",
    "ax0.grid(color=\"gainsboro\", alpha=0.9, ls=\":\")\n",
    "ax0.axhline(y=0, color=\"black\")\n",
    "# ax1.grid(color='gainsboro', alpha=0.7, ls=\":\")\n",
    "plt.title(\"Percentage gain over RandomSampler's HR@10\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Try a different model\n",
    "Write out algorithm\n",
    "SD and MN are the same\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

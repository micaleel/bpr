{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed63ca6-1cc9-4a39-b2a7-e71b999dfba6",
   "metadata": {},
   "source": [
    "# GMF in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d35d79e-6889-4849-8815-5735d467b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext blackcellmagic\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aaf56bc-bd49-46db-a6c2-725d63177119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.extend(['../', '../bpr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16bfca2a-f0de-4b66-9f8d-bae03a79e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "\n",
    "from kutils import load_ml100k, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56664bff-8e12-427c-939d-dfb1aa44b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(load_ml100k('~/datasets/ml-100k/u.data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238ea8a3-d3f5-4099-ae7b-2cfc2e2682cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embed_size, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.embed_u = nn.Embedding(num_embeddings=n_users, embedding_dim=embed_size)\n",
    "        self.embed_i = nn.Embedding(num_embeddings=n_items, embedding_dim=embed_size)\n",
    "        self.fc = nn.Linear(embed_size, 1)\n",
    "\n",
    "        self.embed_u.weight.to(device)\n",
    "        self.embed_i.weight.to(device)\n",
    "\n",
    "        nn.init.normal_(self.embed_u.weight)\n",
    "        nn.init.normal_(self.embed_i.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        user_id = x[:, 0]\n",
    "        item_id = x[:, 1]\n",
    "        user_id.to(self.device)\n",
    "        item_id.to(self.device)\n",
    "        multiplied = self.embed_u(user_id) * self.embed_i(item_id)\n",
    "        x = torch.sigmoid(self.fc(multiplied))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19d5e67-be5f-4544-9841-39cababec6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMFDataset(TorchDataset):\n",
    "    \"\"\"Dataset for pointwise recommendation\"\"\"\n",
    "\n",
    "    def __init__(self, pos_matrix, neg_matrix, n_negatives):\n",
    "        self.pos_matrix = pos_matrix\n",
    "        self.neg_matrix = neg_matrix\n",
    "        self.n_negatives = n_negatives\n",
    "        self.samples = self._create_samples()\n",
    "\n",
    "    def _create_samples(self):\n",
    "        batch = []\n",
    "        for user in range(self.pos_matrix.shape[0]):\n",
    "            pos_items = self.pos_matrix[user].indices\n",
    "            batch.append(\n",
    "                np.column_stack(\n",
    "                    [np.full_like(pos_items, user), pos_items, np.ones_like(pos_items)]\n",
    "                )\n",
    "            )\n",
    "\n",
    "            neg_items = np.random.choice(\n",
    "                a=self.neg_matrix[user].indices,\n",
    "                size=len(pos_items) * self.n_negatives,\n",
    "                replace=True,\n",
    "            )\n",
    "            batch.append(\n",
    "                np.column_stack(\n",
    "                    [np.full_like(neg_items, user), neg_items, np.zeros_like(neg_items)]\n",
    "                )\n",
    "            )\n",
    "        samples = torch.from_numpy(np.concatenate(batch)).type(torch.LongTensor)\n",
    "        return samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.pos_matrix.nnz * self.n_negatives\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert self.samples is not None and len(self.samples) > 0\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b0f714f-d01d-48ad-b82c-a8c3c458d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    loader_train,\n",
    "    epochs,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device=\"cpu\",\n",
    "    eval_metrics=True,\n",
    "    loader_test=None,\n",
    "):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    train_losses = np.zeros(epochs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        losses, n_losses = 0, 0\n",
    "        for batch_idx, batch in enumerate(loader_train):\n",
    "            batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(batch)\n",
    "            target = batch[:, 2].float()\n",
    "            loss = criterion(prediction.view(-1), target.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses += loss.item()\n",
    "\n",
    "        if eval_metrics:\n",
    "            assert loader_test is not None, \"loader_test is required\"\n",
    "            metrics = evaluate(model=model, loader_test=loader_test)\n",
    "\n",
    "        train_losses[epoch] = losses / len(loader_train)\n",
    "        metrics[\"loss\"] = train_losses[epoch]\n",
    "\n",
    "        s = textwrap.indent(pformat(metrics), prefix='  ')\n",
    "        print(f\"Epoch {epoch}\\n{s}\")\n",
    "\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "def evaluate(model, loader_test, topk=10):\n",
    "    model.eval()\n",
    "    item_ids = np.arange(dataset.train_matrix.shape[1])\n",
    "    precisions, recalls, hit_ratios = [], [], []\n",
    "    for user in range(dataset.test_matrix.shape[0]):\n",
    "        rated = dataset.test_matrix[user].indices\n",
    "        with torch.no_grad():\n",
    "            data = np.column_stack([np.full_like(item_ids, user), item_ids])\n",
    "            predictions = model(torch.from_numpy(data)).reshape(-1)\n",
    "            recommendations = torch.argsort(predictions)[-topk:].numpy()\n",
    "            overlap = np.intersect1d(rated, recommendations)\n",
    "            precision = len(overlap) / topk\n",
    "            recall = len(overlap) / len(rated)\n",
    "            hit_ratio = int(len(overlap) > 0)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            hit_ratios.append(hit_ratio)\n",
    "    return {\n",
    "        f\"Precision@{topk}\": np.mean(precisions),\n",
    "        f\"Recall@{topk}\": np.mean(recalls),\n",
    "        f\"HitRatio@{topk}\": np.mean(hit_ratios),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05f60677-86ea-42b3-8f5c-5e2598f726ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "  {'HitRatio@10': 0.08589607635206786,\n",
      "   'Precision@10': 0.009331919406150585,\n",
      "   'Recall@10': 0.003996460316824586,\n",
      "   'loss': 0.5334028985588949}\n",
      "Epoch 1\n",
      "  {'HitRatio@10': 0.0975609756097561,\n",
      "   'Precision@10': 0.01102863202545069,\n",
      "   'Recall@10': 0.004999832748415365,\n",
      "   'loss': 0.45221020705672377}\n",
      "Epoch 2\n",
      "  {'HitRatio@10': 0.09544008483563096,\n",
      "   'Precision@10': 0.010180275715800637,\n",
      "   'Recall@10': 0.004300962045435114,\n",
      "   'loss': 0.4507141452767273}\n",
      "Epoch 3\n",
      "  {'HitRatio@10': 0.13891834570519618,\n",
      "   'Precision@10': 0.015482502651113469,\n",
      "   'Recall@10': 0.008642128071555611,\n",
      "   'loss': 0.45035033948094566}\n",
      "Epoch 4\n",
      "  {'HitRatio@10': 0.20572640509013787,\n",
      "   'Precision@10': 0.026511134676564158,\n",
      "   'Recall@10': 0.013534684409414972,\n",
      "   'loss': 0.4479252805008115}\n",
      "Epoch 5\n",
      "  {'HitRatio@10': 0.26617179215270415,\n",
      "   'Precision@10': 0.03552492046659597,\n",
      "   'Recall@10': 0.017320498216882918,\n",
      "   'loss': 0.43646731667336597}\n",
      "Epoch 6\n",
      "  {'HitRatio@10': 0.34358430540827145,\n",
      "   'Precision@10': 0.04878048780487805,\n",
      "   'Recall@10': 0.022592796116781604,\n",
      "   'loss': 0.40813141875623876}\n",
      "Epoch 7\n",
      "  {'HitRatio@10': 0.3870625662778367,\n",
      "   'Precision@10': 0.05694591728525981,\n",
      "   'Recall@10': 0.026962057335897717,\n",
      "   'loss': 0.37405520168636863}\n",
      "Epoch 8\n",
      "  {'HitRatio@10': 0.4209968186638388,\n",
      "   'Precision@10': 0.06415694591728525,\n",
      "   'Recall@10': 0.03387623596988477,\n",
      "   'loss': 0.3482632684923188}\n",
      "Epoch 9\n",
      "  {'HitRatio@10': 0.4411452810180276,\n",
      "   'Precision@10': 0.06861081654294804,\n",
      "   'Recall@10': 0.038166989583598765,\n",
      "   'loss': 0.33180366023918423}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5334029 , 0.45221021, 0.45071415, 0.45035034, 0.44792528,\n",
       "       0.43646732, 0.40813142, 0.3740552 , 0.34826327, 0.33180366])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "\n",
    "model = GMF(\n",
    "    n_users=dataset.n_users, n_items=dataset.n_items, embed_size=10, device=device\n",
    ")\n",
    "\n",
    "loader_train = DataLoader(\n",
    "    GMFDataset(\n",
    "        pos_matrix=dataset.train_matrix, neg_matrix=dataset.negatives, n_negatives=5\n",
    "    ),\n",
    "    shuffle=True,\n",
    "    batch_size=200,\n",
    ")\n",
    "\n",
    "\n",
    "loader_test = DataLoader(\n",
    "    GMFDataset(\n",
    "        pos_matrix=dataset.test_matrix,\n",
    "        neg_matrix=dataset.negatives,\n",
    "        n_negatives=100,\n",
    "    ),\n",
    "    shuffle=True,\n",
    "    batch_size=200,\n",
    ")\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    loader_train=loader_train,\n",
    "    epochs=10,\n",
    "    criterion=nn.BCELoss(),\n",
    "    optimizer=optim.Adam(model.parameters()),\n",
    "    device=device,\n",
    "    loader_test=loader_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67370110-dcac-422c-8ee8-724cb50dfeda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98acf5d0-04a5-48e8-bde2-491b9e940950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36766ec3-6ac8-4e27-9261-944903554405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7251bd5a-533e-4c0a-9773-283b1c8ed5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
